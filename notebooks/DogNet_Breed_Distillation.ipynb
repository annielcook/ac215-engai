{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6665436ea5a41c193eb96df1a4134d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_126fb1631274479bad57edb4c23f0051",
              "IPY_MODEL_4edc047bde0c498eb176f2b4bf679fd6"
            ],
            "layout": "IPY_MODEL_6c0ef2df828a45d4ba1ac8c9c73522b9"
          }
        },
        "126fb1631274479bad57edb4c23f0051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a106c77ee474992b9a63fd5817e7626",
            "placeholder": "​",
            "style": "IPY_MODEL_85add04763914c4ebaffae4a1dba6bad",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "4edc047bde0c498eb176f2b4bf679fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ed4f5ccccf4bce8ad55f57560fcb4c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e962b80a5d044c4ca11e902a9090a7b4",
            "value": 1
          }
        },
        "6c0ef2df828a45d4ba1ac8c9c73522b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a106c77ee474992b9a63fd5817e7626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85add04763914c4ebaffae4a1dba6bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44ed4f5ccccf4bce8ad55f57560fcb4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e962b80a5d044c4ca11e902a9090a7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bb676a3c13e44cbbdd234ad1cd9199e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6983e67a08264dbd9dc5b5705c6d066b",
              "IPY_MODEL_858a21e7aba3478ba72aaca630746aa6"
            ],
            "layout": "IPY_MODEL_8c96490b2f7246919ae5e9e800340e66"
          }
        },
        "6983e67a08264dbd9dc5b5705c6d066b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf1258726cf841aaa583158017edbedc",
            "placeholder": "​",
            "style": "IPY_MODEL_d81525c980dc4471b5d3a328c96162be",
            "value": "0.025 MB of 0.025 MB uploaded\r"
          }
        },
        "858a21e7aba3478ba72aaca630746aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d514e4089bd24ed1ac30caeecda9fb69",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27c8bef441b44b8f9885bbb63ecdc36b",
            "value": 1
          }
        },
        "8c96490b2f7246919ae5e9e800340e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1258726cf841aaa583158017edbedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81525c980dc4471b5d3a328c96162be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d514e4089bd24ed1ac30caeecda9fb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c8bef441b44b8f9885bbb63ecdc36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc193dd691f94997823dfa77749fdf4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08fd8afff8fa4beea3ad2f27b6cc7158",
              "IPY_MODEL_7ea47feb8bdd405fb9e91238314ff209"
            ],
            "layout": "IPY_MODEL_2fd875e24be9457a82acfde2c33e0146"
          }
        },
        "08fd8afff8fa4beea3ad2f27b6cc7158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2172e8ae139241a1acb615dbab66e748",
            "placeholder": "​",
            "style": "IPY_MODEL_d6a504c616c440e9ab00595d90e99f13",
            "value": "4435.758 MB of 4435.758 MB uploaded (17.424 MB deduped)\r"
          }
        },
        "7ea47feb8bdd405fb9e91238314ff209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a15576d4c6694f56b51bc5a51b991e3b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55237e79f1cf4fff8babd8690f11ee5f",
            "value": 1
          }
        },
        "2fd875e24be9457a82acfde2c33e0146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2172e8ae139241a1acb615dbab66e748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a504c616c440e9ab00595d90e99f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a15576d4c6694f56b51bc5a51b991e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55237e79f1cf4fff8babd8690f11ee5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Library Imports<h1>\n"
      ],
      "metadata": {
        "id": "v_Ldmyi662XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "# Common\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Google\n",
        "from google.cloud import storage\n",
        "\n",
        "# Model\n",
        "import tensorflow as tf\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import Dense, GlobalAvgPool2D, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "import keras\n",
        "\n",
        "# Callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Transfer Learning Models\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.convnext import ConvNeXtBase, ConvNeXtSmall, ConvNeXtLarge\n",
        "from tensorflow.keras.applications.densenet import DenseNet201, DenseNet121, DenseNet169\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "# Weights and Biases\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_WIDTH = 224\n",
        "BATCH_SIZE = 4\n",
        "TRAIN_TEST_SPLIT = 0.8\n",
        "EPOCHS = 30\n",
        "NUM_CLASSES = 120\n",
        "input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS)\n",
        "train_data = []\n",
        "validation_data = []\n",
        "n_steps_training = 0\n",
        "n_steps_validation = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5g1Dew260sj",
        "outputId": "8c9c8d56-892f-421f-f841-3423086c9d94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.35.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSORIZED_DATA_BUCKET_NAME=\"team-engai-dogs-tensorized\"\n",
        "client = storage.Client.from_service_account_json('secrets/data-service-account.json')\n",
        "blobs = client.list_blobs(TENSORIZED_DATA_BUCKET_NAME, prefix='dog_breed_dataset/images/Images')\n",
        "breed_directory_name = 'breed-data'"
      ],
      "metadata": {
        "id": "1Q3k6oYridA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Data Pipeline Function Definitions<h1>\n"
      ],
      "metadata": {
        "id": "ZQYI7xst7F-M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w8k00ZsALRdi"
      },
      "outputs": [],
      "source": [
        "def parse_tfrecord_example(example_proto):\n",
        "  parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "  # Image\n",
        "  #image = tf.image.decode_jpeg(parsed_example['image'])\n",
        "  image = tf.io.decode_raw(parsed_example['image'], tf.uint8)\n",
        "  image.set_shape([NUM_CHANNELS * IMAGE_HEIGHT * IMAGE_WIDTH])\n",
        "  image = tf.reshape(image, [IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS])\n",
        "\n",
        "  # Label\n",
        "  label = tf.cast(parsed_example['label'], tf.int64)\n",
        "  label = tf.one_hot(label, num_classes)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "# Normalize pixels\n",
        "def normalize(image, label):\n",
        "  image = image/255\n",
        "  return image, label\n",
        "\n",
        "def download_data(directory_name, download=True):\n",
        "\n",
        "  if not os.path.exists(directory_name):\n",
        "    os.mkdir(directory_name)\n",
        "\n",
        "  class_to_image_files = {}\n",
        "\n",
        "  for blob in blobs:\n",
        "    image_file_name = blob.name.split('/')[-1]\n",
        "    label = blob.name.split('/')[-2]\n",
        "    if label not in class_to_image_files:\n",
        "      class_to_image_files[label] = []\n",
        "    class_to_image_files[label].append(image_file_name)\n",
        "    if download:\n",
        "      blob.download_to_filename(f'{directory_name}/{image_file_name}')\n",
        "\n",
        "  feature_description = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.string),\n",
        "    'height':tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width':tf.io.FixedLenFeature([], tf.int64),\n",
        "    'channel':tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "    }\n",
        "\n",
        "  return feature_description, class_to_image_files\n",
        "\n",
        "def build_data_pipeline(directory, starting_filename=\"tensorized\", train_dataset_size=TRAIN_TEST_SPLIT):\n",
        "\n",
        "  file_path = os.path.join(directory, ''.join([starting_filename, '*']))\n",
        "  dataset_tfrecord = tf.data.Dataset.list_files('breed-data/tensorized*')\n",
        "  n_files = dataset_tfrecord.cardinality().numpy()\n",
        "\n",
        "  print(f'Loaded {n_files} files')\n",
        "\n",
        "  train_dataset_size = int(TRAIN_TEST_SPLIT * n_files)\n",
        "  val_dataset_size = n_files - train_dataset_size\n",
        "  dataset_tfrecord = dataset_tfrecord.shuffle(n_files)\n",
        "  train_data = dataset_tfrecord.take(train_dataset_size)\n",
        "  validation_data = dataset_tfrecord.skip(train_dataset_size)\n",
        "\n",
        "\n",
        "  # Read the tfrecord files\n",
        "  train_data = train_data.flat_map(tf.data.TFRecordDataset)\n",
        "  train_data = train_data.map(parse_tfrecord_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  train_data = train_data.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  train_data = train_data.batch(BATCH_SIZE)\n",
        "  train_data = train_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  train_data = train_data.repeat()\n",
        "\n",
        "  # Read the tfrecord files\n",
        "  validation_data = validation_data.flat_map(tf.data.TFRecordDataset)\n",
        "  validation_data = validation_data.map(parse_tfrecord_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  validation_data = validation_data.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  validation_data = validation_data.batch(BATCH_SIZE)\n",
        "  validation_data = validation_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  validation_data = validation_data.repeat()\n",
        "\n",
        "  n_steps_training = train_dataset_size // BATCH_SIZE\n",
        "  n_steps_validation = val_dataset_size // BATCH_SIZE\n",
        "\n",
        "  print(f\"Number of training steps: {n_steps_training}\")\n",
        "  print(f\"Number of validation steps: {n_steps_validation}\")\n",
        "\n",
        "  return train_data, validation_data, n_steps_training, n_steps_validation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def tf_dataset_pipeline(train_test_split=TRAIN_TEST_SPLIT):\n",
        "\n",
        "  n_images = 20580\n",
        "  n_train_images = int(n_images * train_test_split)\n",
        "  n_val_images = n_images - n_train_images\n",
        "\n",
        "  ds = tfds.load('stanford_dogs', split='all', shuffle_files=True)\n",
        "\n",
        "  ds = ds.shuffle(n_images)\n",
        "  train_data = ds.take(n_train_images)\n",
        "  validation_data = ds.skip(n_train_images)\n",
        "\n",
        "\n",
        "  # Read the tfrecord files\n",
        "  train_data = train_data.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  train_data = train_data.batch(BATCH_SIZE)\n",
        "  train_data = train_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  train_data = train_data.cache()\n",
        "  train_data = train_data.repeat()\n",
        "\n",
        "  # Read the tfrecord files\n",
        "  validation_data = validation_data.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  validation_data = validation_data.batch(BATCH_SIZE)\n",
        "  validation_data = validation_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  validation_data = validation_data.cache()\n",
        "  validation_data = validation_data.repeat()\n",
        "\n",
        "  n_steps_training = n_train_images // BATCH_SIZE\n",
        "  n_steps_validation = n_val_images // BATCH_SIZE\n",
        "\n",
        "  print(f\"Number of training steps: {n_steps_training}\")\n",
        "  print(f\"Number of validation steps: {n_steps_validation}\")\n",
        "\n",
        "  return train_data, validation_data, n_steps_training, n_steps_validation\n",
        "\n",
        "def preprocess(data):\n",
        "  image, label = data['image'], data['label']\n",
        "  image, label = resize_image(image, label)\n",
        "  image, label = normalize(image, label)\n",
        "  image, label = label_to_onehot(image, label)\n",
        "  return image, label\n",
        "\n",
        "\n",
        "def resize_image(image, label):\n",
        "  image = tf.image.resize(image, [IMAGE_HEIGHT, IMAGE_WIDTH])\n",
        "  return image, label\n",
        "\n",
        "def normalize(image, label):\n",
        "  image = tf.cast(image, tf.float32) / 255.\n",
        "  return image, label\n",
        "\n",
        "def label_to_onehot(image, label):\n",
        "  depth = 120\n",
        "  label = tf.one_hot(label, depth)\n",
        "  return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9F1Gi6svqolj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Model Building and Training Function Definitions<h1>\n",
        "\n"
      ],
      "metadata": {
        "id": "U7M082LXHJiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_teacher_model(num_classes, input_shape, base_architecture, name=\"DogNet-breed\"):\n",
        "  if base_architecture==\"ResNet152v2\":\n",
        "    base_model = ResNet152V2(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base_model.trainable = False # Freeze the Weights\n",
        "  elif base_architecture==\"ConNeXtBase\":\n",
        "    base_model = ConvNeXtBase(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base_model.trainable = False # Freeze the Weights\n",
        "  elif base_architecture==\"ConNeXtLarge\":\n",
        "    base_model = ConvNeXtLarge(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base_model.trainable = False # Freeze the Weights\n",
        "  elif base_architecture==\"DenseNet201\":\n",
        "    base_model = DenseNet201(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base_model.trainable = False # Freeze the Weights\n",
        "\n",
        "\n",
        "  # Model\n",
        "  DogNet_breed = Sequential([\n",
        "      base_model,\n",
        "      GlobalAvgPool2D(),\n",
        "      Dense(500, activation='relu'),\n",
        "      Dense(300, activation='relu'),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dense(num_classes, activation='softmax')\n",
        "  ], name=name)\n",
        "\n",
        "  print(DogNet_breed.summary())\n",
        "\n",
        "  return DogNet_breed\n",
        "\n",
        "\n",
        "def train_model(model,\n",
        "                name,\n",
        "                architecture,\n",
        "                train_data=train_data,\n",
        "                validation_data=validation_data,\n",
        "                n_steps_training=n_steps_training,\n",
        "                n_steps_validation=n_steps_validation,\n",
        "                epochs=EPOCHS,\n",
        "                batch_size=BATCH_SIZE):\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  wandb.init(\n",
        "      project = \"DogNet-breed\",\n",
        "      config = {\n",
        "          #\"learning_rate\": 0.02,\n",
        "          \"epochs\": epochs,\n",
        "          \"architecture\": architecture,\n",
        "          \"batch_size\": batch_size,\n",
        "          \"model_name\": name\n",
        "      },\n",
        "      name = name\n",
        "  )\n",
        "\n",
        "  # Callbacks\n",
        "  callbacks = [\n",
        "      EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, restore_best_weights=True),\n",
        "      WandbCallback(monitor='val_accuracy')\n",
        "  ]\n",
        "\n",
        "  # Train\n",
        "  start_time = time.time()\n",
        "  model.fit(\n",
        "      train_data,\n",
        "      epochs=EPOCHS,\n",
        "      validation_data=validation_data,\n",
        "      callbacks=callbacks,\n",
        "      verbose=1,\n",
        "      steps_per_epoch=n_steps_training,\n",
        "      validation_steps=n_steps_validation\n",
        "      #shuffle=True\n",
        "  )\n",
        "  execution_time = (time.time() - start_time)/60.0\n",
        "  wandb.config.update({\"execution_time\": execution_time})\n",
        "  wandb.run.finish()\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "BNFYBFeI2SJa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_student_model(num_classes, input_shape, base_architecture, name=\"DogNet-breed-student-NoTeacher\"):\n",
        "  if base_architecture==\"ResNet50\":\n",
        "    base_model = ResNet50(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base_model.trainable = False # Freeze the Weights\n",
        "  elif base_architecture==\"ConNextSmall\":\n",
        "    base_model = ConvNeXtSmall(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base_model.trainable = False # Freeze the Weights\n",
        "  elif base_architecture==\"DenseNet121\":\n",
        "    base_model = DenseNet121(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base_model.trainable = False # Freeze the Weights\n",
        "  elif base_architecture==\"DenseNet169\":\n",
        "    base_model = DenseNet169(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base_model.trainable = False # Freeze the Weights\n",
        "\n",
        "\n",
        "  # Model\n",
        "  DogNet_breed = Sequential([\n",
        "      base_model,\n",
        "      GlobalAvgPool2D(),\n",
        "      BatchNormalization(),\n",
        "      Dense(500, activation='relu'),\n",
        "      Dense(300, activation='relu'),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dense(num_classes, activation='softmax')\n",
        "  ], name=name)\n",
        "\n",
        "  print(DogNet_breed.summary())\n",
        "\n",
        "  return DogNet_breed\n",
        "\n"
      ],
      "metadata": {
        "id": "UJ1y6rqhhiAx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Build and Train Teacher Model<h1>"
      ],
      "metadata": {
        "id": "ZJaN_tdVLlz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_architecture = \"ConNeXtLarge\"\n",
        "model_name = ''.join([\"DogNet-breed-teacher\", \"-\",model_architecture])\n",
        "train_data, validation_data, n_steps_training, n_steps_validation = tf_dataset_pipeline(TRAIN_TEST_SPLIT)\n",
        "DogNet_breed_teacher = build_teacher_model(NUM_CLASSES, input_shape, model_architecture)\n",
        "K.clear_session()\n",
        "DogNet_breed_teacher = train_model(\n",
        "    DogNet_breed_teacher,\n",
        "    model_name,\n",
        "    model_architecture,\n",
        "    train_data=train_data,\n",
        "    validation_data=validation_data,\n",
        "    n_steps_training=n_steps_training,\n",
        "    n_steps_validation=n_steps_validation,\n",
        "    epochs=EPOCHS\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5jXUcvagMFJz",
        "outputId": "2774cf10-7d0f-48bd-ac51-15911248be25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training steps: 4116\n",
            "Number of validation steps: 1029\n",
            "Model: \"DogNet-breed\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " convnext_large (Functional  (None, 7, 7, 1536)        196230336 \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1536)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               768500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               60200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 120)               24120     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 197273656 (752.54 MB)\n",
            "Trainable params: 1043320 (3.98 MB)\n",
            "Non-trainable params: 196230336 (748.56 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuanp-heusser\u001b[0m (\u001b[33mengai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231120_120755-pcti6cb2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/engai/DogNet-breed/runs/pcti6cb2' target=\"_blank\">DogNet-breed-teacher-ConNeXtLarge</a></strong> to <a href='https://wandb.ai/engai/DogNet-breed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/engai/DogNet-breed' target=\"_blank\">https://wandb.ai/engai/DogNet-breed</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/engai/DogNet-breed/runs/pcti6cb2' target=\"_blank\">https://wandb.ai/engai/DogNet-breed/runs/pcti6cb2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            " 945/4116 [=====>........................] - ETA: 8:08 - loss: 4.7390 - accuracy: 0.0175"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7f0539391c21>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDogNet_breed_teacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_teacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_architecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m DogNet_breed_teacher = train_model(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mDogNet_breed_teacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-ba6e776a7d15>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, name, architecture, train_data, validation_data, n_steps_training, n_steps_validation, epochs, batch_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m   model.fit(\n\u001b[0m\u001b[1;32m     64\u001b[0m       \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Build and Train Student Model Without Teacher<h1>"
      ],
      "metadata": {
        "id": "W9AQ3mHtNLR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_architecture = \"ConNextSmall\"\n",
        "model_name = ''.join([\"DogNet-breed-student-alone\", \"-\", model_architecture])\n",
        "BATCH_SIZE = 32\n",
        "train_data, validation_data, n_steps_training, n_steps_validation = tf_dataset_pipeline(.8)\n",
        "K.clear_session()\n",
        "DogNet_breed_student = build_student_model(NUM_CLASSES, input_shape, model_architecture)\n",
        "DogNet_breed_student = train_model(\n",
        "    DogNet_breed_student,\n",
        "    model_name,\n",
        "    model_architecture,\n",
        "    train_data, validation_data,\n",
        "    n_steps_training, n_steps_validation\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dc193dd691f94997823dfa77749fdf4b",
            "08fd8afff8fa4beea3ad2f27b6cc7158",
            "7ea47feb8bdd405fb9e91238314ff209",
            "2fd875e24be9457a82acfde2c33e0146",
            "2172e8ae139241a1acb615dbab66e748",
            "d6a504c616c440e9ab00595d90e99f13",
            "a15576d4c6694f56b51bc5a51b991e3b",
            "55237e79f1cf4fff8babd8690f11ee5f"
          ]
        },
        "id": "CxYDyPzNu1H1",
        "outputId": "0f3b0986-d07e-4c51-806b-98041aa31f2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training steps: 514\n",
            "Number of validation steps: 128\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_small_notop.h5\n",
            "198551472/198551472 [==============================] - 7s 0us/step\n",
            "Model: \"DogNet-breed-student-NoTeacher\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " convnext_small (Functional  (None, 7, 7, 768)         49454688  \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 768)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 768)               3072      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               384500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               60200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               24120     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50076880 (191.03 MB)\n",
            "Trainable params: 620656 (2.37 MB)\n",
            "Non-trainable params: 49456224 (188.66 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuanp-heusser\u001b[0m (\u001b[33mengai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231120_154242-lwrq6o7o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/engai/DogNet-breed/runs/lwrq6o7o' target=\"_blank\">DogNet-breed-student-alone-ConNextSmall</a></strong> to <a href='https://wandb.ai/engai/DogNet-breed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/engai/DogNet-breed' target=\"_blank\">https://wandb.ai/engai/DogNet-breed</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/engai/DogNet-breed/runs/lwrq6o7o' target=\"_blank\">https://wandb.ai/engai/DogNet-breed/runs/lwrq6o7o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 4.1545 - accuracy: 0.0932"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 335s 591ms/step - loss: 4.1545 - accuracy: 0.0932 - val_loss: 3.8500 - val_accuracy: 0.1614\n",
            "Epoch 2/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 3.5458 - accuracy: 0.1788"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 284s 547ms/step - loss: 3.5458 - accuracy: 0.1788 - val_loss: 3.3665 - val_accuracy: 0.2141\n",
            "Epoch 3/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 3.1868 - accuracy: 0.2421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 546ms/step - loss: 3.1868 - accuracy: 0.2421 - val_loss: 3.1852 - val_accuracy: 0.2517\n",
            "Epoch 4/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 2.8581 - accuracy: 0.3069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 547ms/step - loss: 2.8581 - accuracy: 0.3069 - val_loss: 3.0600 - val_accuracy: 0.2815\n",
            "Epoch 5/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 2.5337 - accuracy: 0.3717"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 547ms/step - loss: 2.5337 - accuracy: 0.3717 - val_loss: 2.9876 - val_accuracy: 0.3108\n",
            "Epoch 6/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 2.2299 - accuracy: 0.4402"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 548ms/step - loss: 2.2299 - accuracy: 0.4402 - val_loss: 2.8866 - val_accuracy: 0.3462\n",
            "Epoch 7/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 1.9471 - accuracy: 0.5059"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 282s 548ms/step - loss: 1.9471 - accuracy: 0.5059 - val_loss: 2.8667 - val_accuracy: 0.3652\n",
            "Epoch 8/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 1.7182 - accuracy: 0.5574"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 547ms/step - loss: 1.7182 - accuracy: 0.5574 - val_loss: 2.9014 - val_accuracy: 0.3762\n",
            "Epoch 9/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 1.5316 - accuracy: 0.6005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 547ms/step - loss: 1.5316 - accuracy: 0.6005 - val_loss: 2.9170 - val_accuracy: 0.4084\n",
            "Epoch 10/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 1.3719 - accuracy: 0.6422"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 282s 549ms/step - loss: 1.3719 - accuracy: 0.6422 - val_loss: 2.9643 - val_accuracy: 0.4199\n",
            "Epoch 11/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 1.2287 - accuracy: 0.6764"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 282s 548ms/step - loss: 1.2287 - accuracy: 0.6764 - val_loss: 3.0214 - val_accuracy: 0.4346\n",
            "Epoch 12/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 1.1041 - accuracy: 0.7080"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 282s 548ms/step - loss: 1.1041 - accuracy: 0.7080 - val_loss: 3.0295 - val_accuracy: 0.4592\n",
            "Epoch 13/30\n",
            "514/514 [==============================] - 254s 495ms/step - loss: 1.0351 - accuracy: 0.7254 - val_loss: 3.1133 - val_accuracy: 0.4590\n",
            "Epoch 14/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.9419 - accuracy: 0.7479"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 547ms/step - loss: 0.9419 - accuracy: 0.7479 - val_loss: 3.2048 - val_accuracy: 0.4641\n",
            "Epoch 15/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.8446 - accuracy: 0.7715"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 547ms/step - loss: 0.8446 - accuracy: 0.7715 - val_loss: 3.2407 - val_accuracy: 0.4932\n",
            "Epoch 16/30\n",
            "514/514 [==============================] - 254s 495ms/step - loss: 0.8201 - accuracy: 0.7785 - val_loss: 3.2649 - val_accuracy: 0.4824\n",
            "Epoch 17/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.7692 - accuracy: 0.7902"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 282s 548ms/step - loss: 0.7692 - accuracy: 0.7902 - val_loss: 3.3819 - val_accuracy: 0.4941\n",
            "Epoch 18/30\n",
            "514/514 [==============================] - 254s 495ms/step - loss: 0.7245 - accuracy: 0.8035 - val_loss: 3.4351 - val_accuracy: 0.4932\n",
            "Epoch 19/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.6819 - accuracy: 0.8126"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 548ms/step - loss: 0.6819 - accuracy: 0.8126 - val_loss: 3.4107 - val_accuracy: 0.5044\n",
            "Epoch 20/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.8322"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 548ms/step - loss: 0.6118 - accuracy: 0.8322 - val_loss: 3.4760 - val_accuracy: 0.5193\n",
            "Epoch 21/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.8283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 282s 549ms/step - loss: 0.6303 - accuracy: 0.8283 - val_loss: 3.3321 - val_accuracy: 0.5325\n",
            "Epoch 22/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.8441"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 547ms/step - loss: 0.5656 - accuracy: 0.8441 - val_loss: 3.4694 - val_accuracy: 0.5417\n",
            "Epoch 23/30\n",
            "514/514 [==============================] - 255s 495ms/step - loss: 0.5751 - accuracy: 0.8438 - val_loss: 3.5260 - val_accuracy: 0.5344\n",
            "Epoch 24/30\n",
            "514/514 [==============================] - 254s 495ms/step - loss: 0.5339 - accuracy: 0.8505 - val_loss: 3.5064 - val_accuracy: 0.5332\n",
            "Epoch 25/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.4898 - accuracy: 0.8636"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 281s 547ms/step - loss: 0.4898 - accuracy: 0.8636 - val_loss: 3.5065 - val_accuracy: 0.5603\n",
            "Epoch 26/30\n",
            "514/514 [==============================] - 255s 496ms/step - loss: 0.4794 - accuracy: 0.8709 - val_loss: 3.5109 - val_accuracy: 0.5530\n",
            "Epoch 27/30\n",
            "514/514 [==============================] - 254s 495ms/step - loss: 0.4298 - accuracy: 0.8749 - val_loss: 3.5955 - val_accuracy: 0.5593\n",
            "Epoch 28/30\n",
            "514/514 [==============================] - 254s 495ms/step - loss: 0.4606 - accuracy: 0.8737 - val_loss: 3.8166 - val_accuracy: 0.5364\n",
            "Epoch 29/30\n",
            "514/514 [==============================] - 254s 495ms/step - loss: 0.4587 - accuracy: 0.8713 - val_loss: 3.8616 - val_accuracy: 0.5464\n",
            "Epoch 30/30\n",
            "514/514 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.8772"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231120_154242-lwrq6o7o/files/model-best)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 282s 548ms/step - loss: 0.4362 - accuracy: 0.8772 - val_loss: 3.7876 - val_accuracy: 0.5632\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='4435.733 MB of 4435.733 MB uploaded (17.424 MB deduped)\\r'), FloatProgress(value=1…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc193dd691f94997823dfa77749fdf4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▂▃▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇███████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇▇██████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▂▂▂▃▃▄▄▅▅▅▅▄▅▆▆▆▆▆██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.87719</td></tr><tr><td>best_epoch</td><td>29</td></tr><tr><td>best_val_accuracy</td><td>0.56323</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.43624</td></tr><tr><td>val_accuracy</td><td>0.56323</td></tr><tr><td>val_loss</td><td>3.78758</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">DogNet-breed-student-alone-ConNextSmall</strong> at: <a href='https://wandb.ai/engai/DogNet-breed/runs/lwrq6o7o' target=\"_blank\">https://wandb.ai/engai/DogNet-breed/runs/lwrq6o7o</a><br/>Synced 5 W&B file(s), 1 media file(s), 105 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231120_154242-lwrq6o7o/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Model Distillation<h1>"
      ],
      "metadata": {
        "id": "t0AQ_wDEXgdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_from_wandb(artifact_name, project):\n",
        "\n",
        "    try:\n",
        "        wandb.login()\n",
        "        run = wandb.init(project=project, job_type=\"load_model\")\n",
        "        artifact = run.use_artifact(artifact_name, type='model')\n",
        "        artifact_dir = artifact.download()\n",
        "        model = tf.keras.models.load_model(artifact_dir)\n",
        "        run.finish()\n",
        "\n",
        "        print(\"Model loaded successfully\")\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the model: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "7MP_OMQH-t2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(Model):\n",
        "    def __init__(self, teacher, student):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(self, optimizer, metrics, student_loss_fn, distillation_loss_fn, Lambda = 0.1, temperature=3):\n",
        "      \"\"\"\n",
        "      optimizer: Keras optimizer for the student weights\n",
        "      metrics: Keras metrics for evaluation\n",
        "      student_loss_fn: Loss function of difference between student predictions and ground-truth\n",
        "      distillation_loss_fn: Loss function of difference between soft student predictions and soft teacher predictions\n",
        "      lambda: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "      temperature: Temperature for softening probability distributions. Larger temperature gives softer distributions.\n",
        "      \"\"\"\n",
        "      super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "      self.student_loss_fn = student_loss_fn\n",
        "      self.distillation_loss_fn = distillation_loss_fn\n",
        "\n",
        "      #hyper-parameters\n",
        "      self.Lambda = Lambda\n",
        "      self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher (professor)\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.Lambda * student_loss + (1 - self.Lambda) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results"
      ],
      "metadata": {
        "id": "jRAc2DjbSLKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_distillation(teacher_model, student_model_name, student_model_architecture, train_data, validation_data, n_steps_training, n_steps_validation, training_params):\n",
        "  ############################\n",
        "  # Training Params\n",
        "  ############################\n",
        "  learning_rate = training_params[\"learning_rate\"]\n",
        "  Lambda = training_params[\"Lambda\"]\n",
        "  temperature = training_params[\"temperature\"]\n",
        "  epochs = training_params[\"epochs\"]\n",
        "  batch_size = training_params[\"batch_size\"]\n",
        "\n",
        "\n",
        "  # Free up memory\n",
        "  K.clear_session()\n",
        "\n",
        "  # Build Student model\n",
        "  DogNet_breed_student_distillation = build_student_model(NUM_CLASSES, input_shape, model_architecture, student_model_name)\n",
        "\n",
        "  # Build the distiller model\n",
        "  distiller_model = Distiller(teacher=DogNet_breed_teacher, student=DogNet_breed_student_distillation)\n",
        "\n",
        "  # Optimizer\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  # Loss\n",
        "  student_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  #distillation_loss = keras.losses.KLDivergence()\n",
        "  distillation_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "  # Compile\n",
        "  distiller_model.compile(\n",
        "      optimizer=optimizer,\n",
        "      student_loss_fn=student_loss,\n",
        "      distillation_loss_fn=distillation_loss,\n",
        "      metrics=[keras.metrics.CategoricalAccuracy()],\n",
        "      Lambda=Lambda,\n",
        "      temperature=temperature\n",
        "  )\n",
        "\n",
        "  wandb.init(\n",
        "      project = \"DogNet-breed\",\n",
        "      config = {\n",
        "          #\"learning_rate\": 0.02,\n",
        "          \"epochs\": epochs,\n",
        "          \"architecture\": model_architecture,\n",
        "          \"batch_size\": batch_size,\n",
        "          \"model_name\": student_model_name\n",
        "      },\n",
        "      name = student_model_name\n",
        "  )\n",
        "\n",
        "  callbacks = [\n",
        "      EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
        "      #ModelCheckpoint(filepath=student_model_name+\".keras\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True),\n",
        "      WandbCallback(monitor='val_loss')\n",
        "  ]\n",
        "\n",
        "\n",
        "  # Distill teacher to student\n",
        "  start_time = time.time()\n",
        "  training_results = distiller_model.fit(\n",
        "          train_data,\n",
        "          validation_data=validation_data,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks,\n",
        "          steps_per_epoch=n_steps_training,\n",
        "          validation_steps=n_steps_validation)\n",
        "  execution_time = (time.time() - start_time)/60.0\n",
        "  print(\"Training execution time (mins)\",execution_time)\n",
        "\n",
        "  wandb.config.update({\"execution_time\": execution_time})\n",
        "  wandb.run.finish()\n",
        "\n",
        "\n",
        " # # Get model training history\n",
        " # training_history = training_results.history\n",
        "\n",
        " # # Evaluate model\n",
        " # evaluation_results = evaluate_model(distiller_model,validation_data,\n",
        " #               training_history,execution_time,learning_rate, batch_size, epochs, optimizer,\n",
        " #               save=False,\n",
        " #               loss_metrics=[\"student_loss\",\"distillation_loss\",\"val_student_loss\"],\n",
        " #               acc_metrics=[\"sparse_categorical_accuracy\",\"val_sparse_categorical_accuracy\"])\n",
        "\n",
        "\n",
        "  return distiller_model\n"
      ],
      "metadata": {
        "id": "SptfNIrbX04h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "Lambda = 0.75\n",
        "temperature= 12\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "model_architecture = \"DenseNet121\"\n",
        "model_name = ''.join([\"DogNet-breed-student-distilled\", \"-\", model_architecture])\n",
        "\n",
        "training_params = {\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"Lambda\": Lambda,\n",
        "    \"temperature\": temperature,\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE\n",
        "}\n",
        "\n",
        "\n",
        "K.clear_session()\n",
        "DogNet_breed_teacher = load_model_from_wandb(\n",
        "    \"model-DogNet-breed-teacher-ResNet152v2:v13\",\n",
        "    \"DogNet-breed\"\n",
        ")\n",
        "train_data, validation_data, n_steps_training, n_steps_validation = tf_dataset_pipeline(.8)\n",
        "DogNet_breed_student_distilled = train_model_distillation(\n",
        "    DogNet_breed_teacher,\n",
        "    model_name,\n",
        "    model_architecture,\n",
        "    train_data, validation_data,\n",
        "    n_steps_training,\n",
        "    n_steps_validation,\n",
        "    training_params\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e6665436ea5a41c193eb96df1a4134d8",
            "126fb1631274479bad57edb4c23f0051",
            "4edc047bde0c498eb176f2b4bf679fd6",
            "6c0ef2df828a45d4ba1ac8c9c73522b9",
            "1a106c77ee474992b9a63fd5817e7626",
            "85add04763914c4ebaffae4a1dba6bad",
            "44ed4f5ccccf4bce8ad55f57560fcb4c",
            "e962b80a5d044c4ca11e902a9090a7b4",
            "4bb676a3c13e44cbbdd234ad1cd9199e",
            "6983e67a08264dbd9dc5b5705c6d066b",
            "858a21e7aba3478ba72aaca630746aa6",
            "8c96490b2f7246919ae5e9e800340e66",
            "bf1258726cf841aaa583158017edbedc",
            "d81525c980dc4471b5d3a328c96162be",
            "d514e4089bd24ed1ac30caeecda9fb69",
            "27c8bef441b44b8f9885bbb63ecdc36b"
          ]
        },
        "id": "owlJRIdbKvRs",
        "outputId": "c27b73f3-f2cd-4bcd-b5b9-c3702b13fbc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuanp-heusser\u001b[0m (\u001b[33mengai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231116_211930-77b2j18o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/engai/DogNet-breed/runs/77b2j18o' target=\"_blank\">restful-valley-117</a></strong> to <a href='https://wandb.ai/engai/DogNet-breed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/engai/DogNet-breed' target=\"_blank\">https://wandb.ai/engai/DogNet-breed</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/engai/DogNet-breed/runs/77b2j18o' target=\"_blank\">https://wandb.ai/engai/DogNet-breed/runs/77b2j18o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-DogNet-breed-teacher-ResNet152v2:v13, 247.76MB. 5 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   5 of 5 files downloaded.  \n",
            "Done. 0:0:0.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6665436ea5a41c193eb96df1a4134d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">restful-valley-117</strong> at: <a href='https://wandb.ai/engai/DogNet-breed/runs/77b2j18o' target=\"_blank\">https://wandb.ai/engai/DogNet-breed/runs/77b2j18o</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231116_211930-77b2j18o/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n",
            "Number of training steps: 514\n",
            "Number of validation steps: 128\n",
            "Model: \"DogNet-breed-student-distilled-DenseNet121\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1024)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 1024)              4096      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               512500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 300)               150300    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               60200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               24120     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7788720 (29.71 MB)\n",
            "Trainable params: 749168 (2.86 MB)\n",
            "Non-trainable params: 7039552 (26.85 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231116_212007-4jiuqd2k</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/engai/DogNet-breed/runs/4jiuqd2k' target=\"_blank\">DogNet-breed-student-distilled-DenseNet121</a></strong> to <a href='https://wandb.ai/engai/DogNet-breed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/engai/DogNet-breed' target=\"_blank\">https://wandb.ai/engai/DogNet-breed</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/engai/DogNet-breed/runs/4jiuqd2k' target=\"_blank\">https://wandb.ai/engai/DogNet-breed/runs/4jiuqd2k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5577: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.5655 - student_loss: 1.6144 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 230s 398ms/step - categorical_accuracy: 0.5655 - student_loss: 1.6130 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.7549 - val_student_loss: 0.8150\n",
            "Epoch 2/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.7720 - student_loss: 0.7407 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 189s 364ms/step - categorical_accuracy: 0.7720 - student_loss: 0.7403 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8181 - val_student_loss: 0.5269\n",
            "Epoch 3/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.8661 - student_loss: 0.4321 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.8661 - student_loss: 0.4323 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8423 - val_student_loss: 0.5201\n",
            "Epoch 4/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9086 - student_loss: 0.2759 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9086 - student_loss: 0.2761 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8359 - val_student_loss: 0.5051\n",
            "Epoch 5/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9206 - student_loss: 0.2370 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9206 - student_loss: 0.2369 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8557 - val_student_loss: 0.5665\n",
            "Epoch 6/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9316 - student_loss: 0.2040 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9316 - student_loss: 0.2038 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8662 - val_student_loss: 0.4512\n",
            "Epoch 7/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9416 - student_loss: 0.1756 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 186s 362ms/step - categorical_accuracy: 0.9416 - student_loss: 0.1756 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8640 - val_student_loss: 0.5027\n",
            "Epoch 8/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9536 - student_loss: 0.1405 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9536 - student_loss: 0.1405 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8867 - val_student_loss: 0.2455\n",
            "Epoch 9/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9509 - student_loss: 0.1436 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9509 - student_loss: 0.1441 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8889 - val_student_loss: 0.4325\n",
            "Epoch 10/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9619 - student_loss: 0.1199 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9619 - student_loss: 0.1198 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8899 - val_student_loss: 0.4971\n",
            "Epoch 11/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9606 - student_loss: 0.1237 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 186s 363ms/step - categorical_accuracy: 0.9606 - student_loss: 0.1237 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8896 - val_student_loss: 0.4215\n",
            "Epoch 12/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9640 - student_loss: 0.1160 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9640 - student_loss: 0.1159 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8989 - val_student_loss: 0.1617\n",
            "Epoch 13/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9659 - student_loss: 0.1077 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9659 - student_loss: 0.1085 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8992 - val_student_loss: 0.5421\n",
            "Epoch 14/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9729 - student_loss: 0.0915 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 186s 363ms/step - categorical_accuracy: 0.9729 - student_loss: 0.0914 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9084 - val_student_loss: 0.7645\n",
            "Epoch 15/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9733 - student_loss: 0.0933 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9733 - student_loss: 0.0931 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9014 - val_student_loss: 0.6759\n",
            "Epoch 16/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9643 - student_loss: 0.1206 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9643 - student_loss: 0.1209 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9070 - val_student_loss: 0.8882\n",
            "Epoch 17/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9727 - student_loss: 0.0897 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9727 - student_loss: 0.0898 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9016 - val_student_loss: 0.8901\n",
            "Epoch 18/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9739 - student_loss: 0.0882 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9739 - student_loss: 0.0894 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.8879 - val_student_loss: 0.6445\n",
            "Epoch 19/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9682 - student_loss: 0.1115 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9682 - student_loss: 0.1115 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9138 - val_student_loss: 1.2402\n",
            "Epoch 20/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9809 - student_loss: 0.0634 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9809 - student_loss: 0.0633 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9197 - val_student_loss: 1.4283\n",
            "Epoch 21/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9755 - student_loss: 0.0814 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9755 - student_loss: 0.0813 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9109 - val_student_loss: 1.6621\n",
            "Epoch 22/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9754 - student_loss: 0.0872 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9754 - student_loss: 0.0870 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9180 - val_student_loss: 0.9304\n",
            "Epoch 23/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9740 - student_loss: 0.0916 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 186s 363ms/step - categorical_accuracy: 0.9740 - student_loss: 0.0916 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9094 - val_student_loss: 0.8411\n",
            "Epoch 24/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9790 - student_loss: 0.0810 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9790 - student_loss: 0.0808 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9128 - val_student_loss: 1.7036\n",
            "Epoch 25/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9792 - student_loss: 0.0709 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9792 - student_loss: 0.0710 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9060 - val_student_loss: 1.0808\n",
            "Epoch 26/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9777 - student_loss: 0.0839 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9777 - student_loss: 0.0837 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9097 - val_student_loss: 1.5849\n",
            "Epoch 27/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9783 - student_loss: 0.0807 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9783 - student_loss: 0.0805 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9192 - val_student_loss: 1.2893\n",
            "Epoch 28/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9806 - student_loss: 0.0716 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 364ms/step - categorical_accuracy: 0.9806 - student_loss: 0.0714 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9128 - val_student_loss: 0.9610\n",
            "Epoch 29/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9816 - student_loss: 0.0756 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 186s 363ms/step - categorical_accuracy: 0.9816 - student_loss: 0.0756 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9236 - val_student_loss: 1.1319\n",
            "Epoch 30/30\n",
            "514/514 [==============================] - ETA: 0s - categorical_accuracy: 0.9856 - student_loss: 0.0559 - distillation_loss: 4.7875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: categorical_accuracy,student_loss,distillation_loss,val_categorical_accuracy,val_student_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r514/514 [==============================] - 187s 363ms/step - categorical_accuracy: 0.9856 - student_loss: 0.0557 - distillation_loss: 4.7875 - val_categorical_accuracy: 0.9202 - val_student_loss: 1.8534\n",
            "Training execution time (mins) 94.12780819336574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bb676a3c13e44cbbdd234ad1cd9199e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▁▄▆▇▇▇▇▇▇█████████████████████</td></tr><tr><td>distillation_loss</td><td>█▆▆▆▆▃▄▆▇▄▆▆▇▇▂▃▆▇▅▃▅▇██▅▅▁▅▅▅</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>student_loss</td><td>█▅▅▄▂▂▃▂▄▁▂▁▅▁▁▃▂▇▂▁▁▁▂▁▂▁▁▁▂▁</td></tr><tr><td>val_categorical_accuracy</td><td>▁▄▅▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇██▇█▇█▇▇████</td></tr><tr><td>val_student_loss</td><td>▄▃▂▂▃▂▂▁▂▂▂▁▃▃▃▄▄▃▅▆▇▄▄▇▅▇▆▄▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>0.98564</td></tr><tr><td>distillation_loss</td><td>4.78747</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>student_loss</td><td>0.00153</td></tr><tr><td>val_categorical_accuracy</td><td>0.92017</td></tr><tr><td>val_student_loss</td><td>1.85343</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">DogNet-breed-student-distilled-DenseNet121</strong> at: <a href='https://wandb.ai/engai/DogNet-breed/runs/4jiuqd2k' target=\"_blank\">https://wandb.ai/engai/DogNet-breed/runs/4jiuqd2k</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231116_212007-4jiuqd2k/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.saving.save_model(DogNet_breed_student_distilled.student, model_name+'.hdf5')"
      ],
      "metadata": {
        "id": "Jt41MRCPAM3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e469aaf4-d858-46ac-a127-18504b7cbafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1caacdc4e618>:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  tf.keras.saving.save_model(DogNet_breed_student_distilled.student, model_name+'.hdf5')\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, validation_data, n_steps_training, n_steps_validation = tf_dataset_pipeline(TRAIN_TEST_SPLIT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyB9HVpviOII",
        "outputId": "2f8a58d7-fabb-47d0-d4fe-bc442b21ff5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training steps: 4116\n",
            "Number of validation steps: 1029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "loss, accuracy = model.evaluate(validation_data, steps=n_steps_validation)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuQwLw2LjHBk",
        "outputId": "64f1316d-69fd-4385-ff6e-e06c827f1f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1029/1029 [==============================] - 33s 22ms/step - loss: 0.7964 - accuracy: 0.9123\n",
            "Loss:  0.7964034080505371\n",
            "Accuracy:  0.9122934937477112\n"
          ]
        }
      ]
    }
  ]
}